# app/risk_engine.py
import os
import json
from dotenv import load_dotenv
import openai  

print("DEBUG 췅 openai version:", openai.__version__)
load_dotenv()

MODEL_NAME = os.getenv("MODEL_NAME", "gpt-4o-mini")
API_KEY = os.getenv("OPENAI_API_KEY")
USE_MOCK = False

if not API_KEY:
    raise RuntimeError("OPENAI_API_KEY no est치 definida. A침치dela en Render > Environment")

openai.api_key = API_KEY  # 游녣 cambio aqu칤


SYSTEM = """
Comentario: Este es un ejercicio de an치lisis asistido por inteligencia artificial. El objetivo es evaluar c칩mo un modelo LLM puede colaborar con expertos humanos para identificar riesgos relevantes en proyectos ferroviarios en Alemania, tanto obvios como sist칠micos. El resultado ser치 revisado por profesionales humanos, por lo tanto, la calidad, claridad y solidez del razonamiento es m치s importante que la cantidad de resultados.

Act칰as como un comit칠 interdisciplinario compuesto por:
- Ingenieros especializados en planificaci칩n y ejecuci칩n de proyectos de infraestructura ferroviaria en Europa.
- Abogados expertos en derecho de infraestructura y normativa aplicable en Alemania.
- Consultores y analistas con experiencia en evaluaci칩n de riesgos en el sector ferroviario alem치n.

Piensa como si estos perfiles discutieran en conjunto cada riesgo y llegaran a un consenso argumentado.

Tu tarea es leer un documento t칠cnico relacionado con un proyecto ferroviario y detectar *riesgos de planificaci칩n* que puedan generar retrasos, sobrecostos, conflictos contractuales o fallas operativas relevantes.

Devuelve un JSON con exactamente dos listas:
- "intuitive_risks": riesgos t칤picos, previsibles y esperables para equipos experimentados.
- "counterintuitive_risks": riesgos inusuales, sist칠micos, interdisciplinares o dif칤ciles de anticipar.

Cada entrada debe tener esta estructura:
{
  "risk": "...",
  "justification": "...",
  "countermeasure": "...",
  "page": 42,
  "evidence": "Extracto del texto que sirvi칩 de base"
}
"""

def generate_risks(text: str, context: str = "", lang: str = "es") -> dict:
    if USE_MOCK:
        raise RuntimeError("USE_MOCK=True pero el modo estricto est치 activo.")
    if not API_KEY:
        raise RuntimeError("OPENAI_API_KEY no est치 definida. A침치dela en .env")
    if not MODEL_NAME:
        raise RuntimeError("MODEL_NAME no est치 definida")

    # === Sprach-Mapping (Anzeigetext f칲r das Modell) ===
    LANG_MAP = {"de": "Deutsch", "en": "Englisch", "es": "Spanisch"}
    lang_name = LANG_MAP.get(lang, "Deutsch")

    # === System-Prompt in Zielsprache ===
    SYSTEM_BY_LANG = {
        "de": (
            "Du bist ein interdisziplin칛res Fachgremium (Bauingenieurwesen, Vergabe-/Infrastrukturrecht, "
            "Risikomanagement im deutschen Schienenverkehr). Antworte ausnahmslos in Deutsch. "
            "JSON-Schl칲ssel bleiben englisch (risk, justification, countermeasure, page, evidence). "
            "Zitate aus dem Dokument (evidence) nicht 칲bersetzen."
        ),
        "en": (
            "You are an interdisciplinary expert panel (rail civil engineering, procurement/infrastructure law, "
            "risk management in German rail). Respond exclusively in English. "
            "JSON keys must remain in English (risk, justification, countermeasure, page, evidence). "
            "Do not translate document quotes (evidence)."
        ),
        "es": (
            "Eres un panel interdisciplinar (ingenier칤a ferroviaria, derecho de infraestructura, "
            "gesti칩n de riesgos en ferrocarriles). Responde exclusivamente en Espa침ol. "
            "Las claves JSON deben quedar en ingl칠s (risk, justification, countermeasure, page, evidence). "
            "No traduzcas citas del documento (evidence)."
        ),
    }
    system_prompt = SYSTEM_BY_LANG.get(lang, SYSTEM_BY_LANG["de"])

    # === User-Prompt mit harter Sprachvorgabe ===
    user_prompt = f"""
Instrucci칩n cr칤tica / Wichtige Vorgabe / Critical instruction:
Antworte ausschlie륿ich in {lang_name}. Keine Mischsprache. 
JSON-Keys bleiben englisch. Inhalte in {lang_name}. Zitate (evidence) unver칛ndert lassen.

Aufgabe:
Analysiere das folgende Projektdokument (Schieneninfrastruktur) und liefere:
- 5 intuitive Risiken
- 5 kontraintuitive Risiken

Struktur jedes Eintrags:
- "risk"
- "justification"
- "countermeasure"
- "page" (falls unbekannt: sch칛tzen oder leer lassen)
- "evidence" (originales Textzitat aus dem Dokument)

Zus칛tzlicher Kontext (optional):
{context}

Dokument (abgeschnitten auf 18000 Zeichen):
{text[:18000]}

Gib ausschlie륿ich einen g칲ltigen JSON-Objekt-Output mit genau diesen beiden Listen zur칲ck:
- "intuitive_risks": Liste mit 5 Objekten
- "counterintuitive_risks": Liste mit 5 Objekten
""".strip()

    response = openai.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user",   "content": user_prompt},
        ],
        temperature=0.3,
        max_tokens=3000,
        response_format={"type": "json_object"}
    )

    try:
        data = json.loads(response.choices[0].message.content)
    except Exception as e:
        raise RuntimeError(f"No se pudo parsear la respuesta como JSON: {e}")

    if not isinstance(data.get("intuitive_risks"), list) or not isinstance(data.get("counterintuitive_risks"), list):
        raise ValueError("El modelo no devolvi칩 el JSON esperado.")

    for block in data["intuitive_risks"] + data["counterintuitive_risks"]:
        if not all(k in block for k in ["risk", "justification", "countermeasure", "page", "evidence"]):
            raise ValueError("Falta una de las claves requeridas en un riesgo")

    data["source"] = "openai"
    return data

